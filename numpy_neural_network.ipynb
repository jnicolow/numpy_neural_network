{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml # load MNIST data set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math # for exp in sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load MNIST Dataset\n",
    "<img src='media/MNIST_examples.png' alt='MNIST examples'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28a5ede0210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data from sklearn\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target'] # two dataframes\n",
    "y_one_hot_array = pd.get_dummies(y, prefix='class').to_numpy().astype(int) # do onehot encoding\n",
    "# plot first example\n",
    "image = X.iloc[0].values.reshape(28, 28) # reshape it to the form of an image\n",
    "label = y.iloc[0]\n",
    "plt.title(f'This image of a hand written number: {label}')\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim, out_dim = size\n",
    "    limit = np.sqrt(6 / (in_dim + out_dim))\n",
    "    return np.random.uniform(-limit, limit, size)\n",
    "\n",
    "\n",
    "def he_init(size):\n",
    "    in_dim, _ = size\n",
    "    stddev = np.sqrt(2 / in_dim)\n",
    "    return np.random.normal(0, stddev, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 0.531, test loss: 0.373, train acc: None, test acc: 0.890\n",
      "Epoch: 1, train loss: 0.406, test loss: 0.346, train acc: None, test acc: 0.897\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 102\u001b[0m\n\u001b[0;32m    100\u001b[0m     hidden_layer_gradient \u001b[38;5;241m=\u001b[39m hiddenlayer02\u001b[38;5;241m.\u001b[39mbackward(output_gradient\u001b[38;5;241m=\u001b[39mhidden_layer_gradient)  \n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# hidden_layer_gradient = dropoutlayer01.backward(output_gradient =hidden_layer_gradient)    \u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     hidden_layer_gradient \u001b[38;5;241m=\u001b[39m hiddenlayer01\u001b[38;5;241m.\u001b[39mbackward(output_gradient\u001b[38;5;241m=\u001b[39mhidden_layer_gradient)      \n\u001b[0;32m    108\u001b[0m     batch_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    111\u001b[0m running_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m batch_counter \u001b[38;5;66;03m# get average of batch losses for the epoch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jnicolow\\Documents\\courses\\fall2024\\ICS-637\\numpy_neural_network\\linearnn\\linearnnclasses.py:77\u001b[0m, in \u001b[0;36mLinearLayer.backward\u001b[1;34m(self, output_gradient)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m bias_gradient \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_weights\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights, weights_gradient)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_bias\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, bias_gradient)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# print(np.dot(layer_output_gradient, self.weights.T).shape)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jnicolow\\Documents\\courses\\fall2024\\ICS-637\\numpy_neural_network\\linearnn\\optim.py:29\u001b[0m, in \u001b[0;36mAdamOptimizer.update\u001b[1;34m(self, weights, gradients)\u001b[0m\n\u001b[0;32m     26\u001b[0m m_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt) \u001b[38;5;66;03m# bias correction for first moment\u001b[39;00m\n\u001b[0;32m     27\u001b[0m v_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt) \u001b[38;5;66;03m# bias correction for first moment\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m weights \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m m_hat \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39msqrt(v_hat) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon) \u001b[38;5;66;03m# weight update\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Declare simple network\n",
    "import importlib\n",
    "from linearnn import linearnnclasses\n",
    "importlib.reload(linearnnclasses)\n",
    "from linearnn import activationfunctions\n",
    "from linearnn import lossfunctions\n",
    "\n",
    "importlib.reload(activationfunctions)\n",
    "from linearnn.activationfunctions import ReLU, SELU, Tanh, Softmax, DummyActivation\n",
    "from linearnn.optim import AdamOptimizer\n",
    "\n",
    "\n",
    "hidden_layer_sizes = (512, 256, 128)\n",
    "hidden_layer_sizes = (128, 64, 28)\n",
    "\n",
    "learning_rate = 0.07\n",
    "\n",
    "\n",
    "hiddenlayer01 = linearnnclasses.LinearLayer(\n",
    "    input_size=784, \n",
    "    output_size=hidden_layer_sizes[0], \n",
    "    activation_fn_class=ReLU, \n",
    "    weight_init=he_init,\n",
    "    learning_rate=learning_rate,\n",
    "    optimizer=AdamOptimizer # a seperate instace for each layer cuz each layer is a different shape\n",
    ")\n",
    "\n",
    "\n",
    "hiddenlayer02 = linearnnclasses.LinearLayer(\n",
    "    input_size=hidden_layer_sizes[0], \n",
    "    output_size=hidden_layer_sizes[1], \n",
    "    activation_fn_class=SELU, \n",
    "    weight_init=he_init,\n",
    "    learning_rate=learning_rate,\n",
    "    optimizer=AdamOptimizer\n",
    ")\n",
    "\n",
    "\n",
    "hiddenlayer03 = linearnnclasses.LinearLayer(\n",
    "    input_size=hidden_layer_sizes[1], \n",
    "    output_size=hidden_layer_sizes[2], \n",
    "    activation_fn_class=Tanh, \n",
    "    weight_init=xavier_init, # this init is for tanh activation\n",
    "    learning_rate=learning_rate,\n",
    "    optimizer=AdamOptimizer\n",
    ")\n",
    "\n",
    "outputlayer = linearnnclasses.LinearLayer(\n",
    "    input_size=hidden_layer_sizes[2], \n",
    "    output_size=10, \n",
    "    activation_fn_class=DummyActivation, # dummy activation because softmax is incorperated into the loss function\n",
    "    weight_init=he_init,\n",
    "    learning_rate=learning_rate,\n",
    "    optimizer=AdamOptimizer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 200\n",
    "batch_size = 500\n",
    "\n",
    "split_position = 40_000\n",
    "valid_size = 5_000\n",
    "# test set\n",
    "X_test = X.iloc[split_position+valid_size:].values / 255\n",
    "y_test = y_one_hot_array[split_position+valid_size:,:]\n",
    "y_truth_test = np.argmax(y_test, axis=1) # convert from onehot to just the correct number\n",
    "# validation set\n",
    "X_valid = X.iloc[split_position- valid_size:split_position].values / 255\n",
    "y_valid = y_one_hot_array[split_position- valid_size:split_position]\n",
    "y_truth_valid = np.argmax(y_test, axis=1) # convert from onehot to just the correct number\n",
    "split_position = 40_000 # reinitialized to decide training data size\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "epochs = list(range(num_epochs)) # if stopping training prematurely this could be an issue\n",
    "\n",
    "training_loss_class = lossfunctions.CategoricalCrossEntropy(l2_lambda=0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # itterate over batches\n",
    "    running_loss = 0.0\n",
    "    batch_counter = 0 # keep track of number of epochs to get average of training losses\n",
    "    for i in range(0, X.iloc[0:split_position].shape[0]-batch_size, batch_size):\n",
    "        x_batch = X.iloc[i:i+batch_size].values / 255\n",
    "        y_batch = y_one_hot_array[i:i+batch_size, :]\n",
    "\n",
    "        # forwaed pass\n",
    "        hidden_output = hiddenlayer01.forward(x_batch, backprop=True)\n",
    "        # hidden_output = dropoutlayer01.forward(hidden_output, training=True)\n",
    "        hidden_output = hiddenlayer02.forward(hidden_output, backprop=True)\n",
    "        hidden_output = hiddenlayer03.forward(hidden_output, backprop=True)\n",
    "\n",
    "        y_hat = outputlayer.forward(hidden_output, backprop=True) # do forward pass saving inputs at each step\n",
    "\n",
    "\n",
    "        # compute loss\n",
    "        loss = training_loss_class.forward(y=y_batch, y_hat=y_hat, weights=outputlayer.weights)\n",
    "        running_loss += loss\n",
    "\n",
    "\n",
    "        # back propagation\n",
    "        loss_gradient = training_loss_class.derivative(y=y_batch, y_hat=y_hat)\n",
    "\n",
    "        output_layer_gradient = outputlayer.backward(output_gradient=loss_gradient)#, y = y_batch) # have to pass y for derivative of soft max\n",
    "\n",
    "        hidden_layer_gradient = hiddenlayer03.backward(output_gradient=output_layer_gradient)      \n",
    "        hidden_layer_gradient = hiddenlayer02.backward(output_gradient=hidden_layer_gradient)  \n",
    "        # hidden_layer_gradient = dropoutlayer01.backward(output_gradient =hidden_layer_gradient)    \n",
    "        hidden_layer_gradient = hiddenlayer01.backward(output_gradient=hidden_layer_gradient)      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        batch_counter += 1\n",
    "\n",
    "\n",
    "    running_loss /= batch_counter # get average of batch losses for the epoch\n",
    "    train_losses.append(running_loss)\n",
    "\n",
    "    # predicted_nums = np.argmax(y_hat, axis=1)\n",
    "    # correct_predictions = np.sum(predicted_nums == y_truth)\n",
    "    # train_accuracy = correct_predictions / y_truth.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "    # Evaluation on Test set (only done once per epoch)\n",
    "    hidden_output = hiddenlayer01.forward(X_valid, backprop=False) # back prop as false because no need store intermediate values\n",
    "    hidden_output = hiddenlayer02.forward(hidden_output, backprop=False)\n",
    "    hidden_output = hiddenlayer03.forward(hidden_output, backprop=False)\n",
    "    y_hat = outputlayer.forward(hidden_output, backprop=False) # back prop as false because no need store intermediate values\n",
    "    \n",
    "    val_loss = lossfunctions.CategoricalCrossEntropy(l2_lambda=0.0).forward(y=y_valid, y_hat=y_hat)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    predicted_nums = np.argmax(y_hat, axis=1)\n",
    "    correct_predictions = np.sum(predicted_nums == y_truth_valid)\n",
    "    val_accuracy = correct_predictions / y_truth_valid.shape[0]\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f'Epoch: {epoch}, train loss: {running_loss:0.3f}, validation loss: {val_loss:0.3f}, train acc: {None}, validation acc: {val_accuracy:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_layers_test_94.1acc.pkl']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [hiddenlayer01, hiddenlayer02, hiddenlayer03, outputlayer]\n",
    "import joblib\n",
    "joblib.dump(layers, r'trained_layers_test_94acc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x296908eff50>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = list(range(len(test_losses))) # just incase it was stopped early\n",
    "\n",
    "# Assuming train_losses, test_losses, and epochs are already populated\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(epochs, test_accuracies, label='test_acc', color='blue', marker=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (77,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Plot training loss\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, train_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Plot testing loss\u001b[39;00m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs, test_losses, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Loss\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jim\\anaconda3\\envs\\numpy_env\\Lib\\site-packages\\matplotlib\\pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3796\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3797\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3798\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3799\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3800\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jim\\anaconda3\\envs\\numpy_env\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\Jim\\anaconda3\\envs\\numpy_env\\Lib\\site-packages\\matplotlib\\axes\\_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[0;32m    297\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\Jim\\anaconda3\\envs\\numpy_env\\Lib\\site-packages\\matplotlib\\axes\\_base.py:486\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    483\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (77,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = list(range(len(test_losses))) # just incase it was stopped early\n",
    "\n",
    "# Assuming train_losses, test_losses, and epochs are already populated\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(epochs, train_losses, label='Training Loss', color='blue', marker=None)\n",
    "\n",
    "# Plot testing loss\n",
    "plt.plot(epochs, test_losses, label='Testing Loss', color='orange', marker=None)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Training and Testing Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n"
     ]
    }
   ],
   "source": [
    "x_batch = X.iloc[0:100].values / 255\n",
    "print(x_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sequential model class (under developement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "5\n",
      "1\n",
      "Adding: LinearLayer input:784, output:512, activation:<class 'linearnn.activationfunctions.ReLU'>\n",
      "2\n",
      "Adding: LinearLayer input:512, output:256, activation:<class 'linearnn.activationfunctions.SELU'>\n",
      "3\n",
      "Adding: LinearLayer input:256, output:128, activation:<class 'linearnn.activationfunctions.Tanh'>\n",
      "4\n",
      "Adding: LinearLayer input:128, output:10, activation:<class 'linearnn.activationfunctions.DummyActivation'>\n",
      "model built\n"
     ]
    }
   ],
   "source": [
    "from linearnn import linearnnclasses\n",
    "from linearnn import lossfunctions\n",
    "from linearnn.activationfunctions import ReLU, SELU, Tanh, DummyActivation\n",
    "# from linearnn.optim import AdamOptimizer\n",
    "from linearnn import optim\n",
    "import importlib\n",
    "importlib.reload(linearnnclasses)\n",
    "importlib.reload(optim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sequential_model = linearnnclasses.SequentialModel(\n",
    "    input_size=784,\n",
    "    output_size=10,\n",
    "    hidden_layers=(512, 256, 128), \n",
    "    activation_fn_classes=(ReLU, SELU, Tanh, DummyActivation),\n",
    "    weight_init=(he_init, he_init, xavier_init, he_init),\n",
    "    loss_fn_class = lossfunctions.CategoricalCrossEntropy,\n",
    "    learning_rate = 0.07,\n",
    "    optimizer=None#optim.AdamOptimizer # with default settings (see linearnn/optim.py)\n",
    ")\n",
    "# sequential_model.forward(x_batch)\n",
    "# sequential_model.backward(x_batch, y_one_hot_array[0:500, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: 1.827, test loss: 2.531, train acc: None, test acc: 0.070\n",
      "Epoch: 1, train loss: 1.761, test loss: 2.446, train acc: None, test acc: 0.081\n",
      "Epoch: 2, train loss: 1.706, test loss: 2.372, train acc: None, test acc: 0.096\n",
      "Epoch: 3, train loss: 1.658, test loss: 2.306, train acc: None, test acc: 0.118\n",
      "Epoch: 4, train loss: 1.614, test loss: 2.244, train acc: None, test acc: 0.148\n",
      "Epoch: 5, train loss: 1.573, test loss: 2.186, train acc: None, test acc: 0.186\n",
      "Epoch: 6, train loss: 1.534, test loss: 2.130, train acc: None, test acc: 0.227\n",
      "Epoch: 7, train loss: 1.496, test loss: 2.077, train acc: None, test acc: 0.273\n",
      "Epoch: 8, train loss: 1.461, test loss: 2.026, train acc: None, test acc: 0.320\n",
      "Epoch: 9, train loss: 1.426, test loss: 1.978, train acc: None, test acc: 0.364\n",
      "Epoch: 10, train loss: 1.394, test loss: 1.931, train acc: None, test acc: 0.405\n",
      "Epoch: 11, train loss: 1.362, test loss: 1.886, train acc: None, test acc: 0.443\n",
      "Epoch: 12, train loss: 1.332, test loss: 1.843, train acc: None, test acc: 0.475\n",
      "Epoch: 13, train loss: 1.302, test loss: 1.801, train acc: None, test acc: 0.504\n",
      "Epoch: 14, train loss: 1.274, test loss: 1.761, train acc: None, test acc: 0.531\n",
      "Epoch: 15, train loss: 1.247, test loss: 1.722, train acc: None, test acc: 0.554\n",
      "Epoch: 16, train loss: 1.221, test loss: 1.685, train acc: None, test acc: 0.574\n",
      "Epoch: 17, train loss: 1.196, test loss: 1.649, train acc: None, test acc: 0.590\n",
      "Epoch: 18, train loss: 1.172, test loss: 1.615, train acc: None, test acc: 0.607\n",
      "Epoch: 19, train loss: 1.149, test loss: 1.582, train acc: None, test acc: 0.621\n",
      "Epoch: 20, train loss: 1.126, test loss: 1.550, train acc: None, test acc: 0.633\n",
      "Epoch: 21, train loss: 1.104, test loss: 1.519, train acc: None, test acc: 0.645\n",
      "Epoch: 22, train loss: 1.084, test loss: 1.489, train acc: None, test acc: 0.657\n",
      "Epoch: 23, train loss: 1.063, test loss: 1.460, train acc: None, test acc: 0.668\n",
      "Epoch: 24, train loss: 1.044, test loss: 1.433, train acc: None, test acc: 0.678\n",
      "Epoch: 25, train loss: 1.025, test loss: 1.406, train acc: None, test acc: 0.687\n",
      "Epoch: 26, train loss: 1.007, test loss: 1.380, train acc: None, test acc: 0.695\n",
      "Epoch: 27, train loss: 0.990, test loss: 1.355, train acc: None, test acc: 0.702\n",
      "Epoch: 28, train loss: 0.973, test loss: 1.331, train acc: None, test acc: 0.710\n",
      "Epoch: 29, train loss: 0.957, test loss: 1.308, train acc: None, test acc: 0.718\n",
      "Epoch: 30, train loss: 0.941, test loss: 1.286, train acc: None, test acc: 0.725\n",
      "Epoch: 31, train loss: 0.926, test loss: 1.264, train acc: None, test acc: 0.731\n",
      "Epoch: 32, train loss: 0.911, test loss: 1.244, train acc: None, test acc: 0.736\n",
      "Epoch: 33, train loss: 0.897, test loss: 1.223, train acc: None, test acc: 0.742\n",
      "Epoch: 34, train loss: 0.884, test loss: 1.204, train acc: None, test acc: 0.747\n",
      "Epoch: 35, train loss: 0.871, test loss: 1.185, train acc: None, test acc: 0.752\n",
      "Epoch: 36, train loss: 0.858, test loss: 1.167, train acc: None, test acc: 0.756\n",
      "Epoch: 37, train loss: 0.845, test loss: 1.149, train acc: None, test acc: 0.761\n",
      "Epoch: 38, train loss: 0.833, test loss: 1.132, train acc: None, test acc: 0.764\n",
      "Epoch: 39, train loss: 0.822, test loss: 1.116, train acc: None, test acc: 0.768\n",
      "Epoch: 40, train loss: 0.811, test loss: 1.100, train acc: None, test acc: 0.772\n",
      "Epoch: 41, train loss: 0.800, test loss: 1.084, train acc: None, test acc: 0.776\n",
      "Epoch: 42, train loss: 0.789, test loss: 1.069, train acc: None, test acc: 0.779\n",
      "Epoch: 43, train loss: 0.779, test loss: 1.055, train acc: None, test acc: 0.782\n",
      "Epoch: 44, train loss: 0.769, test loss: 1.041, train acc: None, test acc: 0.784\n",
      "Epoch: 45, train loss: 0.760, test loss: 1.027, train acc: None, test acc: 0.787\n",
      "Epoch: 46, train loss: 0.750, test loss: 1.014, train acc: None, test acc: 0.789\n",
      "Epoch: 47, train loss: 0.741, test loss: 1.001, train acc: None, test acc: 0.792\n",
      "Epoch: 48, train loss: 0.732, test loss: 0.989, train acc: None, test acc: 0.794\n",
      "Epoch: 49, train loss: 0.724, test loss: 0.976, train acc: None, test acc: 0.797\n",
      "Epoch: 50, train loss: 0.715, test loss: 0.965, train acc: None, test acc: 0.799\n",
      "Epoch: 51, train loss: 0.707, test loss: 0.953, train acc: None, test acc: 0.801\n",
      "Epoch: 52, train loss: 0.700, test loss: 0.942, train acc: None, test acc: 0.804\n",
      "Epoch: 53, train loss: 0.692, test loss: 0.931, train acc: None, test acc: 0.806\n",
      "Epoch: 54, train loss: 0.684, test loss: 0.920, train acc: None, test acc: 0.808\n",
      "Epoch: 55, train loss: 0.677, test loss: 0.910, train acc: None, test acc: 0.809\n",
      "Epoch: 56, train loss: 0.670, test loss: 0.900, train acc: None, test acc: 0.811\n",
      "Epoch: 57, train loss: 0.663, test loss: 0.890, train acc: None, test acc: 0.813\n",
      "Epoch: 58, train loss: 0.656, test loss: 0.881, train acc: None, test acc: 0.815\n",
      "Epoch: 59, train loss: 0.650, test loss: 0.872, train acc: None, test acc: 0.816\n",
      "Epoch: 60, train loss: 0.643, test loss: 0.863, train acc: None, test acc: 0.818\n",
      "Epoch: 61, train loss: 0.637, test loss: 0.854, train acc: None, test acc: 0.820\n",
      "Epoch: 62, train loss: 0.631, test loss: 0.845, train acc: None, test acc: 0.822\n",
      "Epoch: 63, train loss: 0.625, test loss: 0.837, train acc: None, test acc: 0.823\n",
      "Epoch: 64, train loss: 0.620, test loss: 0.829, train acc: None, test acc: 0.825\n",
      "Epoch: 65, train loss: 0.614, test loss: 0.822, train acc: None, test acc: 0.827\n",
      "Epoch: 66, train loss: 0.609, test loss: 0.815, train acc: None, test acc: 0.829\n",
      "Epoch: 67, train loss: 0.605, test loss: 0.809, train acc: None, test acc: 0.830\n",
      "Epoch: 68, train loss: 0.601, test loss: 0.807, train acc: None, test acc: 0.829\n",
      "Epoch: 69, train loss: 0.604, test loss: 0.820, train acc: None, test acc: 0.826\n",
      "Epoch: 70, train loss: 0.617, test loss: 0.845, train acc: None, test acc: 0.819\n",
      "Epoch: 71, train loss: 0.638, test loss: 0.877, train acc: None, test acc: 0.806\n",
      "Epoch: 72, train loss: 0.657, test loss: 0.903, train acc: None, test acc: 0.798\n",
      "Epoch: 73, train loss: 0.679, test loss: 0.924, train acc: None, test acc: 0.795\n",
      "Epoch: 74, train loss: 0.696, test loss: 0.941, train acc: None, test acc: 0.795\n",
      "Epoch: 75, train loss: 0.702, test loss: 0.947, train acc: None, test acc: 0.798\n",
      "Epoch: 76, train loss: 0.703, test loss: 0.948, train acc: None, test acc: 0.804\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m     x_batch \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     23\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y_one_hot_array[i:i\u001b[38;5;241m+\u001b[39mbatch_size, :]\n\u001b[1;32m---> 24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m sequential_model\u001b[38;5;241m.\u001b[39mbackward(x_batch, y_batch) \u001b[38;5;66;03m# forward pass is incorperated in backward function\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     29\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m sequential_model\u001b[38;5;241m.\u001b[39mforward(X_test, backprop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jim\\OneDrive\\Documents\\courses\\ics-637\\numpy_neural_network\\linearnn\\linearnnclasses.py:152\u001b[0m, in \u001b[0;36mSequentialModel.backward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    150\u001b[0m training_loss_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn_class(l2_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m) \u001b[38;5;66;03m# turn l2 regularization off\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# performs a backward pass through the model\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x, backprop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# backprop true to save self.linear_transform and self.activation in each layer\u001b[39;00m\n\u001b[0;32m    154\u001b[0m loss \u001b[38;5;241m=\u001b[39m training_loss_class\u001b[38;5;241m.\u001b[39mforward(y\u001b[38;5;241m=\u001b[39my, y_hat\u001b[38;5;241m=\u001b[39my_hat, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;66;03m# pass the weights for the last layer\u001b[39;00m\n\u001b[0;32m    155\u001b[0m loss_gradient \u001b[38;5;241m=\u001b[39m training_loss_class\u001b[38;5;241m.\u001b[39mderivative(y\u001b[38;5;241m=\u001b[39my, y_hat\u001b[38;5;241m=\u001b[39my_hat) \u001b[38;5;66;03m# needs to be combined with softmax\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jim\\OneDrive\\Documents\\courses\\ics-637\\numpy_neural_network\\linearnn\\linearnnclasses.py:144\u001b[0m, in \u001b[0;36mSequentialModel.forward\u001b[1;34m(self, x, backprop)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)):\n\u001b[0;32m    143\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[i]\n\u001b[1;32m--> 144\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mforward(x, backprop) \u001b[38;5;66;03m# if back prop true linear layer will remeber linear transform and activation output\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Jim\\OneDrive\\Documents\\courses\\ics-637\\numpy_neural_network\\linearnn\\linearnnclasses.py:36\u001b[0m, in \u001b[0;36mLinearLayer.forward\u001b[1;34m(self, x, backprop)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backprop: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m=\u001b[39m x \u001b[38;5;66;03m# remeber input to the layer for backprop\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# linear transformation\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m linear_transformation_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;66;03m# Wx + b\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backprop:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_transrom \u001b[38;5;241m=\u001b[39m linear_transformation_output \u001b[38;5;66;03m# saving these to be used in backpropigation\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# activation\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 500\n",
    "\n",
    "split_position = 50_000\n",
    "X_test = X.iloc[split_position:].values / 255\n",
    "y_test = y_one_hot_array[split_position:,:]\n",
    "y_truth = np.argmax(y_test, axis=1) # convert from onehot to just the correct number\n",
    "split_position = 50_000 # reinitialized to decide training data size\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "epochs = list(range(num_epochs)) # if stopping training prematurely this could be an issue\n",
    "\n",
    "test_loss_fn_class = lossfunctions.CategoricalCrossEntropy(l2_lambda=0.0)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # itterate over batches\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, X.iloc[:split_position].shape[0]-batch_size, batch_size):\n",
    "        x_batch = X.iloc[i:i+batch_size].values / 255\n",
    "        y_batch = y_one_hot_array[i:i+batch_size, :]\n",
    "        loss = sequential_model.backward(x_batch, y_batch) # forward pass is incorperated in backward function\n",
    "     \n",
    "        running_loss += loss\n",
    "    \n",
    "\n",
    "    y_hat = sequential_model.forward(X_test, backprop=False)\n",
    "    test_loss = test_loss_fn_class.forward(y=y_test, y_hat=y_hat)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    predicted_nums = np.argmax(y_hat, axis=1)\n",
    "    correct_predictions = np.sum(predicted_nums == y_truth)\n",
    "    test_accuracy = correct_predictions / y_truth.shape[0]\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f'Epoch: {epoch}, train loss: {running_loss/(X.shape[0]/batch_size):0.3f}, test loss: {test_loss:0.3f}, train acc: {None}, test acc: {test_accuracy:0.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-100:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sequential_model.forward(X[-100:-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 7, 7, 7, 1, 9, 4, 2, 5, 7, 7, 1, 7, 7, 7, 7, 6, 1, 9, 7, 8,\n",
       "       7, 7, 6, 7, 7, 2, 6, 7, 6, 9, 2, 1, 6, 9, 7, 1, 7, 7, 1, 5, 8, 8,\n",
       "       9, 0, 9, 7, 9, 6, 7, 1, 8, 7, 9, 1, 9, 5, 2, 9, 5, 9, 7, 7, 7, 7,\n",
       "       7, 7, 8, 7, 7, 7, 6, 5, 7, 7, 9, 7, 9, 7, 7, 9, 9, 0, 7, 9, 1, 7,\n",
       "       7, 7, 7, 8, 7, 7, 7, 2, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices = np.argmax(preds, axis=1)\n",
    "max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 7, 8, 9, 7, 8, 6,\n",
       "       4, 1, 9, 3, 8, 4, 4, 7, 0, 1, 9, 2, 8, 7, 8, 2, 6, 0, 6, 5, 3, 3,\n",
       "       3, 9, 1, 4, 0, 6, 1, 0, 0, 6, 2, 1, 1, 7, 7, 8, 4, 6, 0, 7, 0, 3,\n",
       "       6, 8, 7, 1, 5, 2, 4, 9, 4, 3, 6, 4, 1, 7, 2, 6, 5, 0, 1, 2, 3, 4,\n",
       "       5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_one_hot_array[-100:-1, :], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
